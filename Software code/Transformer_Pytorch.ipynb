{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import math\n",
    "import torch\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataset\n",
    "class HemoglobinDataset(Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    # Knowing the length can help dataloader automatically generate batches\n",
    "    def __len__(self):\n",
    "        return len(self.X)  # return the number of sample\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        X = self.X[idx]\n",
    "        y = self.y[idx]\n",
    "        return X, y\n",
    "    \n",
    "def set_seed(seed):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)  # Numpy module.\n",
    "    random.seed(seed)  # Python random module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. read load\n",
    "def load_data(a):\n",
    "    data = []\n",
    "    labels = []\n",
    "    for i in a:\n",
    "        df = pd.read_csv(i)\n",
    "        if df.shape[0] == 249:\n",
    "            df['Gender'] = df['Gender'].map({'Male': 1, 'Female': 0})\n",
    "            features = df[['Red (a.u)', 'Infra Red (a.u)', 'Gender']].values\n",
    "            label = df['Hemoglobin (g/dL)'].values[-1] \n",
    "            data.append(features)\n",
    "            labels.append(label)\n",
    "    return np.array(data), np.array(labels)\n",
    "\n",
    "# Get all file paths\n",
    "address = \"../Code/Raw dataset\" \n",
    "datapath = [os.path.join(address, f) for f in os.listdir(address) if f.endswith('.csv')]\n",
    "# load data\n",
    "X, y = load_data(datapath)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Data Standardization\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Standardization\n",
    "X_train_shape = X_train.shape\n",
    "X_val_shape = X_val.shape\n",
    "X_test_shape = X_test.shape\n",
    "\n",
    "X_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train_shape)\n",
    "X_val = scaler.transform(X_val.reshape(-1, X_val.shape[-1])).reshape(X_val_shape)\n",
    "X_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets\n",
    "train_dataset = HemoglobinDataset(X_train, y_train)\n",
    "val_dataset = HemoglobinDataset(X_val, y_val)\n",
    "test_dataset = HemoglobinDataset(X_test, y_test)\n",
    "\n",
    "# create loader\n",
    "# shuffle = True means shuffling the data order to prevent the model from learning its sequential features, which can lead to overfitting\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Module is the base class of neural network modules in PyTorch. All custom neural networks should inherit this class.\n",
    "# nn.Module allows overriding the forward() method to define custom forward propagation logic;\n",
    "# Automatically register parameters. All submodules or nn.Parameter defined in the __init__ method will be automatically added to the model's parameter list.\n",
    "# You can use model.parameters() to access all parameters, which is convenient for initializing the optimizer.\n",
    "class InputEmbeddings(nn.Module):\n",
    "    def __init__(self, input_dim, d_model):\n",
    "        super(InputEmbeddings, self).__init__()\n",
    "        # Used for class inheritance: ensure that the parent class method is called correctly and avoid repeated calls to the parent class\n",
    "        # def doesn't need super because they are all independent\n",
    "        \n",
    "        # super(InputEmbeddings, self) This usage is used in Python 2.x to specify the parent class to be called and the instance of the current class\n",
    "        # InputEmbeddings is the current class name, indicating that you want to search the MRO list upward from this class\n",
    "        # self is the instance of the current class, indicating that super() should use this instance as the basis to search its inheritance chain\n",
    "        self.linear = nn.Linear(input_dim, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, seq_len):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "\n",
    "        pe = torch.zeros(seq_len, d_model)\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        # Make pe not be updated as a model parameter, but will be saved and loaded with the model when saving and loading the model\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + (self.pe[:, :x.shape[1], :]).requires_grad_(False)\n",
    "\n",
    "class LayerNormalization(nn.Module):\n",
    "    def __init__(self, d_model, eps=1e-6):\n",
    "        super(LayerNormalization, self).__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(d_model))\n",
    "        self.beta = nn.Parameter(torch.zeros(d_model))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim=True)\n",
    "        std = x.std(-1, keepdim=True)\n",
    "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
    "\n",
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, d_model, dim_feedforward, dropout):\n",
    "        super(FeedForward, self).__init__()\n",
    "        self.linear1 = nn.Linear(d_model, dim_feedforward)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear2 = nn.Linear(dim_feedforward, d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear2(self.dropout(torch.relu(self.linear1(x))))\n",
    "\n",
    "class ResidualConnection(nn.Module):\n",
    "    def __init__(self, d_model, dropout):\n",
    "        super(ResidualConnection, self).__init__()\n",
    "        self.norm = LayerNormalization(d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x, sublayer):\n",
    "        return self.norm(x + self.dropout(sublayer(x)))\n",
    "\n",
    "class MultiHeadAttentionBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dropout):\n",
    "        super(MultiHeadAttentionBlock, self).__init__()\n",
    "        self.d_model = d_model\n",
    "        self.nhead = nhead\n",
    "        self.d_k = d_model // nhead\n",
    "\n",
    "        self.w_q = nn.Linear(d_model, d_model) # Wq\n",
    "        self.w_k = nn.Linear(d_model, d_model) # Wk\n",
    "        self.w_v = nn.Linear(d_model, d_model) # Wv\n",
    "        self.w_o = nn.Linear(d_model, d_model) # Wo\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def ScaleDotProductAttention(self, Q, K, V, mask=None):\n",
    "        batch_size, head, length, d_tensor = K.size()\n",
    "        score = (Q @ K.transpose(-2, -1)) / math.sqrt(d_tensor) # matmul and scaled\n",
    "\n",
    "        if mask is not None:\n",
    "            score = score.masked_fill(mask == 0, -1e9) # mask\n",
    "        score = torch.softmax(score, dim=-1) # softmax\n",
    "        score = self.dropout(score)\n",
    "        output = score @ V # matmul\n",
    "        return output, score\n",
    "\n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        query = self.w_q(q) # (batch size, seq_len, d_model)\n",
    "        key = self.w_k(k) # (batch size, seq_len, d_model)\n",
    "        value = self.w_v(v) # (batch size, seq_len, d_model)\n",
    "\n",
    "        # (batch size, seq_len, d_model) --> (batch size, seq_len, nhead, d_k) --> (batch size, nhead, seq_len, d_k)\n",
    "        Q = query.view(query.shape[0], query.shape[1], self.nhead, self.d_k).transpose(1, 2)\n",
    "        K = key.view(key.shape[0], key.shape[1], self.nhead, self.d_k).transpose(1, 2)\n",
    "        V = value.view(value.shape[0], value.shape[1], self.nhead, self.d_k).transpose(1, 2)\n",
    "\n",
    "        # Apply scaled dot-product attention\n",
    "        out, scores = self.ScaleDotProductAttention(Q, K, V, mask)\n",
    "\n",
    "        # Concatenate heads and put through final linear layer\n",
    "        # (batch size, nhead, seq_len, d_k) --> (batch size, seq_len, nhead, d_k) --> (batch size, seq_len, d_model)\n",
    "        # d_model = nhead * d_k\n",
    "        out = out.transpose(1, 2).contiguous().view(out.shape[0], -1, self.nhead * self.d_k)\n",
    "        return self.w_o(out)\n",
    "\n",
    "class EncoderBlock(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward, dropout):\n",
    "        super(EncoderBlock, self).__init__()\n",
    "        self.self_attn = MultiHeadAttentionBlock(d_model, nhead, dropout)\n",
    "        self.ffn = FeedForward(d_model, dim_feedforward, dropout)\n",
    "        self.residuals = nn.ModuleList([ResidualConnection(d_model, dropout) for _ in range(2)])\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        x = self.residuals[0](x, lambda x: self.self_attn(x, x, x, src_mask))\n",
    "        x = self.residuals[1](x, self.ffn)\n",
    "        return x\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, nhead, dim_feedforward, dropout):\n",
    "        super(Encoder, self).__init__()\n",
    "        self.layers = nn.ModuleList([EncoderBlock(d_model, nhead, dim_feedforward, dropout) for _ in range(num_layers)])\n",
    "        self.norm = LayerNormalization(d_model)\n",
    "\n",
    "    def forward(self, x, src_mask=None):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, src_mask)\n",
    "        return self.norm(x)\n",
    "\n",
    "class Regression(nn.Module):\n",
    "    def __init__(self, d_model, output_dim):\n",
    "        super(Regression, self).__init__()\n",
    "        self.fc = nn.Linear(d_model, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x[:, -1, :])  # Take the output of the last time step\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder, src_embed, src_pos, regression):\n",
    "        super(Transformer, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.src_embed = src_embed\n",
    "        self.src_pos = src_pos\n",
    "        self.regression = regression\n",
    "\n",
    "    def encode(self, src):\n",
    "        src = self.src_embed(src)\n",
    "        src = self.src_pos(src)\n",
    "        return self.encoder(src)\n",
    "\n",
    "    def project(self, x):\n",
    "        return self.regression(x)\n",
    "\n",
    "def build_transformer(input_dim, output_dim, d_model, N, h, dropout, d_ff, seq_len):\n",
    "    src_embed = InputEmbeddings(input_dim, d_model)\n",
    "    src_pos = PositionalEncoding(d_model, seq_len)\n",
    "    encoder = Encoder(N, d_model, h, d_ff, dropout)\n",
    "    \n",
    "    regression = Regression(d_model, output_dim)\n",
    "    \n",
    "    transformer = Transformer(encoder, src_embed, src_pos, regression)\n",
    "    \n",
    "    for p in transformer.parameters():\n",
    "        if p.dim() > 1:\n",
    "            nn.init.xavier_uniform_(p)\n",
    "    \n",
    "    return transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    # set init values \n",
    "    epoch_loss = 0.0\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        labels = labels.to(device)\n",
    "        # Gradient clearing\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "\n",
    "        encoder_output = model.encode(inputs)\n",
    "        outputs = model.project(encoder_output)\n",
    "        outputs = outputs.squeeze(-1)\n",
    "\n",
    "        # calculate the batch loss\n",
    "        loss = criterion(outputs, labels)\n",
    "        # backward pass\n",
    "        loss.backward()\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "        # record loss\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss / len(train_loader)\n",
    "\n",
    "# The core idea of ​​gradient optimization is to use gradient information to gradually adjust the weights so that the loss function reaches the minimum value.\n",
    "# Gradient descent algorithm updates model parameters along the negative direction of the gradient of the loss function to achieve the goal of minimizing the loss.\n",
    "\n",
    "def validate_one_epoch(model, valid_loader, criterion, device):\n",
    "    # initialise\n",
    "    valid_loss = 0.0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in valid_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward pass\n",
    "            encoder_output = model.encode(inputs)\n",
    "            outputs = model.project(encoder_output)\n",
    "            outputs = outputs.squeeze(-1)\n",
    "\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # record loss\n",
    "            valid_loss += loss.item()\n",
    "    return valid_loss / len(valid_loader)\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "            # forward pass\n",
    "            encoder_output = model.encode(inputs)\n",
    "            outputs = model.project(encoder_output)\n",
    "            outputs = outputs.squeeze(-1)\n",
    "\n",
    "            # calculate the batch loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "    test_loss /= len(test_loader)  \n",
    "    return test_loss\n",
    "\n",
    "def get_predictions(model, test_loader, device):\n",
    "    model.eval()\n",
    "    all_outputs = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs = inputs.to(device)\n",
    "            # forward pass\n",
    "            encoder_output = model.encode(inputs)\n",
    "            outputs = model.project(encoder_output)\n",
    "            outputs = outputs.squeeze(-1)\n",
    "            \n",
    "            all_outputs.append(outputs.cpu().numpy())\n",
    "            all_labels.append(labels.cpu().numpy())\n",
    "    all_outputs = np.concatenate(all_outputs, axis=0)\n",
    "    all_labels = np.concatenate(all_labels, axis=0)\n",
    "    return all_outputs, all_labels\n",
    "\n",
    "def fit(model, epochs, device, criterion, optimizer, train_loader, valid_loader=None):\n",
    "    # initialise\n",
    "    train_loss_min = np.Inf\n",
    "    valid_loss_min = np.Inf\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        # clear useless data\n",
    "        gc.collect()\n",
    "        \n",
    "        print(f\"{'='*50}\")\n",
    "        print(f\"EPOCH {epoch} - TRAINING...\")\n",
    "        train_loss = train_one_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        print(f\"\\n\\t[TRAIN] EPOCH {epoch} - LOSS: {train_loss}\\n\")\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        if train_loss < train_loss_min:\n",
    "            train_loss_min = train_loss\n",
    "\n",
    "        gc.collect()\n",
    "\n",
    "        if valid_loader is not None:\n",
    "            gc.collect()\n",
    "            \n",
    "            print(f\"EPOCH {epoch} - VALIDATING...\")\n",
    "            valid_loss = validate_one_epoch(model, valid_loader, criterion, device)\n",
    "            print(f\"\\t[VALID] LOSS: {valid_loss}\\n\")\n",
    "            valid_losses.append(valid_loss)\n",
    "            gc.collect()\n",
    "            # show if validation loss has decreased\n",
    "            if valid_loss <= valid_loss_min and epoch != 1:\n",
    "                print(f\"Validation loss decreased ({valid_loss_min:.4f} --> {valid_loss:.4f}).\")\n",
    "                valid_loss_min = valid_loss\n",
    "    \n",
    "    print(f\"Minimum Training Loss: {train_loss_min:.4f}\")\n",
    "    print(f\"Minimum Validation Loss: {valid_loss_min:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        \"train_loss\": train_losses,\n",
    "        \"valid_loss\": valid_losses,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIALIZING TRAINING \n",
      "Start Time: 2024-08-30 04:00:47.918174\n",
      "==================================================\n",
      "EPOCH 1 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 1 - LOSS: 58.7770930926005\n",
      "\n",
      "EPOCH 1 - VALIDATING...\n",
      "\t[VALID] LOSS: 7.8202924728393555\n",
      "\n",
      "==================================================\n",
      "EPOCH 2 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 2 - LOSS: 8.133326371510824\n",
      "\n",
      "EPOCH 2 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.9159317016601562\n",
      "\n",
      "Validation loss decreased (inf --> 1.9159).\n",
      "==================================================\n",
      "EPOCH 3 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 3 - LOSS: 5.99504288037618\n",
      "\n",
      "EPOCH 3 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.341100215911865\n",
      "\n",
      "==================================================\n",
      "EPOCH 4 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 4 - LOSS: 5.469499746958415\n",
      "\n",
      "EPOCH 4 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.566943407058716\n",
      "\n",
      "==================================================\n",
      "EPOCH 5 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 5 - LOSS: 5.451894521713257\n",
      "\n",
      "EPOCH 5 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.10347843170166\n",
      "\n",
      "==================================================\n",
      "EPOCH 6 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 6 - LOSS: 3.8621915181477866\n",
      "\n",
      "EPOCH 6 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.535740375518799\n",
      "\n",
      "==================================================\n",
      "EPOCH 7 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 7 - LOSS: 4.597738583882649\n",
      "\n",
      "EPOCH 7 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.684647798538208\n",
      "\n",
      "==================================================\n",
      "EPOCH 8 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 8 - LOSS: 4.488296270370483\n",
      "\n",
      "EPOCH 8 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.1452908515930176\n",
      "\n",
      "==================================================\n",
      "EPOCH 9 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 9 - LOSS: 3.636315186818441\n",
      "\n",
      "EPOCH 9 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.8227488994598389\n",
      "\n",
      "Validation loss decreased (1.9159 --> 1.8227).\n",
      "==================================================\n",
      "EPOCH 10 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 10 - LOSS: 3.6969145933787027\n",
      "\n",
      "EPOCH 10 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.540161371231079\n",
      "\n",
      "==================================================\n",
      "EPOCH 11 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 11 - LOSS: 3.796297550201416\n",
      "\n",
      "EPOCH 11 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.9373769760131836\n",
      "\n",
      "==================================================\n",
      "EPOCH 12 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 12 - LOSS: 4.362615426381429\n",
      "\n",
      "EPOCH 12 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.9496256113052368\n",
      "\n",
      "==================================================\n",
      "EPOCH 13 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 13 - LOSS: 3.8011585076649985\n",
      "\n",
      "EPOCH 13 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.3226284980773926\n",
      "\n",
      "==================================================\n",
      "EPOCH 14 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 14 - LOSS: 4.026180585225423\n",
      "\n",
      "EPOCH 14 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.8213281631469727\n",
      "\n",
      "Validation loss decreased (1.8227 --> 1.8213).\n",
      "==================================================\n",
      "EPOCH 15 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 15 - LOSS: 3.4989287853240967\n",
      "\n",
      "EPOCH 15 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.1657614707946777\n",
      "\n",
      "==================================================\n",
      "EPOCH 16 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 16 - LOSS: 3.662811358769735\n",
      "\n",
      "EPOCH 16 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.06396222114563\n",
      "\n",
      "==================================================\n",
      "EPOCH 17 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 17 - LOSS: 4.1844338575998945\n",
      "\n",
      "EPOCH 17 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.8370492458343506\n",
      "\n",
      "==================================================\n",
      "EPOCH 18 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 18 - LOSS: 4.708780606587728\n",
      "\n",
      "EPOCH 18 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.822327971458435\n",
      "\n",
      "==================================================\n",
      "EPOCH 19 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 19 - LOSS: 5.1052695115407305\n",
      "\n",
      "EPOCH 19 - VALIDATING...\n",
      "\t[VALID] LOSS: 1.8642406463623047\n",
      "\n",
      "==================================================\n",
      "EPOCH 20 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 20 - LOSS: 3.855489810307821\n",
      "\n",
      "EPOCH 20 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.6263110637664795\n",
      "\n",
      "==================================================\n",
      "EPOCH 21 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 21 - LOSS: 3.1077574094136557\n",
      "\n",
      "EPOCH 21 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.4919843673706055\n",
      "\n",
      "==================================================\n",
      "EPOCH 22 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 22 - LOSS: 4.844792366027832\n",
      "\n",
      "EPOCH 22 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.254551410675049\n",
      "\n",
      "==================================================\n",
      "EPOCH 23 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 23 - LOSS: 2.89884082476298\n",
      "\n",
      "EPOCH 23 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.4310717582702637\n",
      "\n",
      "==================================================\n",
      "EPOCH 24 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 24 - LOSS: 2.282648762067159\n",
      "\n",
      "EPOCH 24 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.45415997505188\n",
      "\n",
      "==================================================\n",
      "EPOCH 25 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 25 - LOSS: 2.559872269630432\n",
      "\n",
      "EPOCH 25 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.0751497745513916\n",
      "\n",
      "==================================================\n",
      "EPOCH 26 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 26 - LOSS: 2.3892196814219155\n",
      "\n",
      "EPOCH 26 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.619479179382324\n",
      "\n",
      "==================================================\n",
      "EPOCH 27 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 27 - LOSS: 2.474093039830526\n",
      "\n",
      "EPOCH 27 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.023552894592285\n",
      "\n",
      "==================================================\n",
      "EPOCH 28 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 28 - LOSS: 2.4204339186350503\n",
      "\n",
      "EPOCH 28 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.6530487537384033\n",
      "\n",
      "==================================================\n",
      "EPOCH 29 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 29 - LOSS: 2.14106293519338\n",
      "\n",
      "EPOCH 29 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.275275230407715\n",
      "\n",
      "==================================================\n",
      "EPOCH 30 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 30 - LOSS: 2.3127287228902182\n",
      "\n",
      "EPOCH 30 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.134420871734619\n",
      "\n",
      "==================================================\n",
      "EPOCH 31 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 31 - LOSS: 2.0120925108591714\n",
      "\n",
      "EPOCH 31 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.561048984527588\n",
      "\n",
      "==================================================\n",
      "EPOCH 32 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 32 - LOSS: 2.442589044570923\n",
      "\n",
      "EPOCH 32 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.9699158668518066\n",
      "\n",
      "==================================================\n",
      "EPOCH 33 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 33 - LOSS: 2.2443332274754844\n",
      "\n",
      "EPOCH 33 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.893947124481201\n",
      "\n",
      "==================================================\n",
      "EPOCH 34 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 34 - LOSS: 2.2152344981829324\n",
      "\n",
      "EPOCH 34 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.101438522338867\n",
      "\n",
      "==================================================\n",
      "EPOCH 35 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 35 - LOSS: 2.299380977948507\n",
      "\n",
      "EPOCH 35 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.479879379272461\n",
      "\n",
      "==================================================\n",
      "EPOCH 36 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 36 - LOSS: 2.5593960285186768\n",
      "\n",
      "EPOCH 36 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.728611946105957\n",
      "\n",
      "==================================================\n",
      "EPOCH 37 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 37 - LOSS: 2.3585084676742554\n",
      "\n",
      "EPOCH 37 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.060201644897461\n",
      "\n",
      "==================================================\n",
      "EPOCH 38 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 38 - LOSS: 2.2471137046813965\n",
      "\n",
      "EPOCH 38 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.586211681365967\n",
      "\n",
      "==================================================\n",
      "EPOCH 39 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 39 - LOSS: 3.116931597391764\n",
      "\n",
      "EPOCH 39 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.006897449493408\n",
      "\n",
      "==================================================\n",
      "EPOCH 40 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 40 - LOSS: 2.9382008711496987\n",
      "\n",
      "EPOCH 40 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.52825927734375\n",
      "\n",
      "==================================================\n",
      "EPOCH 41 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 41 - LOSS: 3.147759278615316\n",
      "\n",
      "EPOCH 41 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.357483386993408\n",
      "\n",
      "==================================================\n",
      "EPOCH 42 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 42 - LOSS: 2.454675833384196\n",
      "\n",
      "EPOCH 42 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.5890419483184814\n",
      "\n",
      "==================================================\n",
      "EPOCH 43 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 43 - LOSS: 2.0463785330454507\n",
      "\n",
      "EPOCH 43 - VALIDATING...\n",
      "\t[VALID] LOSS: 5.11149787902832\n",
      "\n",
      "==================================================\n",
      "EPOCH 44 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 44 - LOSS: 2.4658427238464355\n",
      "\n",
      "EPOCH 44 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.3543992042541504\n",
      "\n",
      "==================================================\n",
      "EPOCH 45 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 45 - LOSS: 2.7500489552815757\n",
      "\n",
      "EPOCH 45 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.756250858306885\n",
      "\n",
      "==================================================\n",
      "EPOCH 46 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 46 - LOSS: 2.900495449701945\n",
      "\n",
      "EPOCH 46 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.134420871734619\n",
      "\n",
      "==================================================\n",
      "EPOCH 47 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 47 - LOSS: 2.2474535703659058\n",
      "\n",
      "EPOCH 47 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.326484680175781\n",
      "\n",
      "==================================================\n",
      "EPOCH 48 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 48 - LOSS: 2.2138744990030923\n",
      "\n",
      "EPOCH 48 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.2343246936798096\n",
      "\n",
      "==================================================\n",
      "EPOCH 49 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 49 - LOSS: 1.8550986051559448\n",
      "\n",
      "EPOCH 49 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.1971189975738525\n",
      "\n",
      "==================================================\n",
      "EPOCH 50 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 50 - LOSS: 2.240339756011963\n",
      "\n",
      "EPOCH 50 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.8360543251037598\n",
      "\n",
      "==================================================\n",
      "EPOCH 51 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 51 - LOSS: 1.95058540503184\n",
      "\n",
      "EPOCH 51 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.41308856010437\n",
      "\n",
      "==================================================\n",
      "EPOCH 52 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 52 - LOSS: 2.227883219718933\n",
      "\n",
      "EPOCH 52 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.99834942817688\n",
      "\n",
      "==================================================\n",
      "EPOCH 53 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 53 - LOSS: 2.102974534034729\n",
      "\n",
      "EPOCH 53 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.3327934741973877\n",
      "\n",
      "==================================================\n",
      "EPOCH 54 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 54 - LOSS: 2.746593197186788\n",
      "\n",
      "EPOCH 54 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.2883362770080566\n",
      "\n",
      "==================================================\n",
      "EPOCH 55 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 55 - LOSS: 2.3895922104517617\n",
      "\n",
      "EPOCH 55 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.342630386352539\n",
      "\n",
      "==================================================\n",
      "EPOCH 56 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 56 - LOSS: 2.2384641567866006\n",
      "\n",
      "EPOCH 56 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.2953579425811768\n",
      "\n",
      "==================================================\n",
      "EPOCH 57 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 57 - LOSS: 2.3813388347625732\n",
      "\n",
      "EPOCH 57 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.956934452056885\n",
      "\n",
      "==================================================\n",
      "EPOCH 58 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 58 - LOSS: 2.7512842814127603\n",
      "\n",
      "EPOCH 58 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.4229788780212402\n",
      "\n",
      "==================================================\n",
      "EPOCH 59 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 59 - LOSS: 3.360946774482727\n",
      "\n",
      "EPOCH 59 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.1400766372680664\n",
      "\n",
      "==================================================\n",
      "EPOCH 60 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 60 - LOSS: 3.2349442640940347\n",
      "\n",
      "EPOCH 60 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.787529468536377\n",
      "\n",
      "==================================================\n",
      "EPOCH 61 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 61 - LOSS: 2.8570801417032876\n",
      "\n",
      "EPOCH 61 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.86318302154541\n",
      "\n",
      "==================================================\n",
      "EPOCH 62 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 62 - LOSS: 1.946731448173523\n",
      "\n",
      "EPOCH 62 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.221397399902344\n",
      "\n",
      "==================================================\n",
      "EPOCH 63 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 63 - LOSS: 2.478881279627482\n",
      "\n",
      "EPOCH 63 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.7352378368377686\n",
      "\n",
      "==================================================\n",
      "EPOCH 64 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 64 - LOSS: 2.8169147968292236\n",
      "\n",
      "EPOCH 64 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.8853402137756348\n",
      "\n",
      "==================================================\n",
      "EPOCH 65 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 65 - LOSS: 3.856529712677002\n",
      "\n",
      "EPOCH 65 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.6900436878204346\n",
      "\n",
      "==================================================\n",
      "EPOCH 66 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 66 - LOSS: 2.8803045749664307\n",
      "\n",
      "EPOCH 66 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.5957999229431152\n",
      "\n",
      "==================================================\n",
      "EPOCH 67 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 67 - LOSS: 3.4620304107666016\n",
      "\n",
      "EPOCH 67 - VALIDATING...\n",
      "\t[VALID] LOSS: 5.256674766540527\n",
      "\n",
      "==================================================\n",
      "EPOCH 68 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 68 - LOSS: 2.4736355543136597\n",
      "\n",
      "EPOCH 68 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.8426952362060547\n",
      "\n",
      "==================================================\n",
      "EPOCH 69 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 69 - LOSS: 2.399219274520874\n",
      "\n",
      "EPOCH 69 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.509690761566162\n",
      "\n",
      "==================================================\n",
      "EPOCH 70 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 70 - LOSS: 2.1681907971700034\n",
      "\n",
      "EPOCH 70 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.720148801803589\n",
      "\n",
      "==================================================\n",
      "EPOCH 71 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 71 - LOSS: 2.554885983467102\n",
      "\n",
      "EPOCH 71 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.0962138175964355\n",
      "\n",
      "==================================================\n",
      "EPOCH 72 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 72 - LOSS: 1.836946169535319\n",
      "\n",
      "EPOCH 72 - VALIDATING...\n",
      "\t[VALID] LOSS: 4.202610492706299\n",
      "\n",
      "==================================================\n",
      "EPOCH 73 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 73 - LOSS: 2.6031688849131265\n",
      "\n",
      "EPOCH 73 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.0280113220214844\n",
      "\n",
      "==================================================\n",
      "EPOCH 74 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 74 - LOSS: 2.3620920976003013\n",
      "\n",
      "EPOCH 74 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.5169291496276855\n",
      "\n",
      "==================================================\n",
      "EPOCH 75 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 75 - LOSS: 2.197961171468099\n",
      "\n",
      "EPOCH 75 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.6994218826293945\n",
      "\n",
      "==================================================\n",
      "EPOCH 76 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 76 - LOSS: 2.472502072652181\n",
      "\n",
      "EPOCH 76 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.5921120643615723\n",
      "\n",
      "==================================================\n",
      "EPOCH 77 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 77 - LOSS: 1.6981201171875\n",
      "\n",
      "EPOCH 77 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.6447033882141113\n",
      "\n",
      "==================================================\n",
      "EPOCH 78 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 78 - LOSS: 2.2057979504267373\n",
      "\n",
      "EPOCH 78 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.4275243282318115\n",
      "\n",
      "==================================================\n",
      "EPOCH 79 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 79 - LOSS: 2.084958036740621\n",
      "\n",
      "EPOCH 79 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.9999992847442627\n",
      "\n",
      "==================================================\n",
      "EPOCH 80 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 80 - LOSS: 2.1782310009002686\n",
      "\n",
      "EPOCH 80 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.0062952041625977\n",
      "\n",
      "==================================================\n",
      "EPOCH 81 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 81 - LOSS: 1.953421990076701\n",
      "\n",
      "EPOCH 81 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.0048611164093018\n",
      "\n",
      "==================================================\n",
      "EPOCH 82 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 82 - LOSS: 2.165414253870646\n",
      "\n",
      "EPOCH 82 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.668531894683838\n",
      "\n",
      "==================================================\n",
      "EPOCH 83 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 83 - LOSS: 2.2982751925786338\n",
      "\n",
      "EPOCH 83 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.585707187652588\n",
      "\n",
      "==================================================\n",
      "EPOCH 84 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 84 - LOSS: 2.4038215478261313\n",
      "\n",
      "EPOCH 84 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.2573485374450684\n",
      "\n",
      "==================================================\n",
      "EPOCH 85 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 85 - LOSS: 1.8868991136550903\n",
      "\n",
      "EPOCH 85 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.5988404750823975\n",
      "\n",
      "==================================================\n",
      "EPOCH 86 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 86 - LOSS: 2.10759445031484\n",
      "\n",
      "EPOCH 86 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.1404666900634766\n",
      "\n",
      "==================================================\n",
      "EPOCH 87 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 87 - LOSS: 2.314417004585266\n",
      "\n",
      "EPOCH 87 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.1305766105651855\n",
      "\n",
      "==================================================\n",
      "EPOCH 88 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 88 - LOSS: 2.8132035732269287\n",
      "\n",
      "EPOCH 88 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.55066180229187\n",
      "\n",
      "==================================================\n",
      "EPOCH 89 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 89 - LOSS: 2.1728057066599527\n",
      "\n",
      "EPOCH 89 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.884270429611206\n",
      "\n",
      "==================================================\n",
      "EPOCH 90 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 90 - LOSS: 2.1905448834101358\n",
      "\n",
      "EPOCH 90 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.38615083694458\n",
      "\n",
      "==================================================\n",
      "EPOCH 91 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 91 - LOSS: 2.6074426571528115\n",
      "\n",
      "EPOCH 91 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.5523061752319336\n",
      "\n",
      "==================================================\n",
      "EPOCH 92 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 92 - LOSS: 2.498482823371887\n",
      "\n",
      "EPOCH 92 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.57391619682312\n",
      "\n",
      "==================================================\n",
      "EPOCH 93 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 93 - LOSS: 1.8288602034250896\n",
      "\n",
      "EPOCH 93 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.1725497245788574\n",
      "\n",
      "==================================================\n",
      "EPOCH 94 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 94 - LOSS: 2.449318528175354\n",
      "\n",
      "EPOCH 94 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.695066452026367\n",
      "\n",
      "==================================================\n",
      "EPOCH 95 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 95 - LOSS: 2.1527103583017984\n",
      "\n",
      "EPOCH 95 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.4881742000579834\n",
      "\n",
      "==================================================\n",
      "EPOCH 96 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 96 - LOSS: 2.681762377421061\n",
      "\n",
      "EPOCH 96 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.3367340564727783\n",
      "\n",
      "==================================================\n",
      "EPOCH 97 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 97 - LOSS: 3.4070727825164795\n",
      "\n",
      "EPOCH 97 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.262643814086914\n",
      "\n",
      "==================================================\n",
      "EPOCH 98 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 98 - LOSS: 2.00875993569692\n",
      "\n",
      "EPOCH 98 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.8423237800598145\n",
      "\n",
      "==================================================\n",
      "EPOCH 99 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 99 - LOSS: 2.131819566090902\n",
      "\n",
      "EPOCH 99 - VALIDATING...\n",
      "\t[VALID] LOSS: 3.494166135787964\n",
      "\n",
      "==================================================\n",
      "EPOCH 100 - TRAINING...\n",
      "\n",
      "\t[TRAIN] EPOCH 100 - LOSS: 2.4325599670410156\n",
      "\n",
      "EPOCH 100 - VALIDATING...\n",
      "\t[VALID] LOSS: 2.5847551822662354\n",
      "\n",
      "Minimum Training Loss: 1.6981\n",
      "Minimum Validation Loss: 1.8213\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "input_dim = 3\n",
    "output_dim = 1\n",
    "seq_len = 249\n",
    "# d_model value can be 3 (the number of features) or larger values (better choice), such as 64, 128, 256, 512\n",
    "d_model = 64\n",
    "# nhead value is value that can divide d_model value exactly without remainder. And, it is usually 2, 4, 8.\n",
    "h = 4\n",
    "# number of layer\n",
    "N = 1\n",
    "# dim_feedforward should be times of d_model, normally set to 4 times.\n",
    "d_ff = 128\n",
    "# this is the default value\n",
    "dropout = 0.1\n",
    "learning_rate = 0.09\n",
    "epoch = 100\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "model = build_transformer(input_dim, output_dim, d_model, N, h, dropout, d_ff, seq_len)\n",
    "model = model.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(f\"INITIALIZING TRAINING \")\n",
    "start_time = datetime.now()\n",
    "print(f\"Start Time: {start_time}\")\n",
    "\n",
    "logs = fit(\n",
    "    model=model,\n",
    "    epochs=epoch,\n",
    "    device=device,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    train_loader=train_loader,\n",
    "    valid_loader=val_loader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.5690\n",
      "Predictions: 13.9, 14.5, 12.0, 11.9, 13.7, 14.3, 11.9, 14.3, 11.9, 11.9, 15.4\n",
      "True Labels: 11.0, 13.7, 12.4, 11.6, 14.4, 13.8, 13.2, 14.3, 11.6, 12.9, 17.5\n",
      "R² score: 0.4658287149081093\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate_model(model, test_loader, criterion, device)\n",
    "print(f'Test Loss: {test_loss:.4f}')\n",
    "\n",
    "predictions, true_labels = get_predictions(model, test_loader, device)\n",
    "print(f'Predictions: {\", \".join([f\"{pred:.1f}\" for pred in predictions])}')\n",
    "print(f'True Labels: {\", \".join([f\"{label:.1f}\" for label in true_labels])}')\n",
    "\n",
    "# Calculate R²\n",
    "r2 = r2_score(true_labels, predictions)\n",
    "print(\"R² score:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,6))\n",
    "ax.plot(logs['train_loss'], color='b', label=\"Training Loss\")\n",
    "ax.plot(logs['valid_loss'], color='r', label=\"Validation Loss\")\n",
    "legend = ax.legend(loc='best', shadow=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, 'Transformer_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amls2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
